# generate_reports.py
# CSV in  -> two JSONs in out/  -> optional PDFs/HTML (client + internal)
# Model defaults to gpt-5-mini; switch with --model

import os, io, re, json, math, argparse
from datetime import datetime
from typing import List, Dict, Any, Tuple

import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI

# Optional PDF export (falls back to HTML-only if not available)
from jinja2 import Environment, BaseLoader, select_autoescape
try:
    from weasyprint import HTML  # optional; on Windows may require extra libs
    HAVE_WEASY = True
except Exception:
    HAVE_WEASY = False

# ---------------------------------------------------
# ENV
# ---------------------------------------------------
load_dotenv(override=True)  # .env wins over machine/user env

# ---------------------------------------------------
# CONFIG
# ---------------------------------------------------
INPUT_DIR = "in"
OUTPUT_DIR = "out"
DEFAULT_MODEL = "gpt-5-mini"     # per your spec; override with --model
TEMPERATURE = None               # use model default; some models (e.g., gpt-5-mini) don't allow custom temperature

# HTML templates for rendering PDFs (simple, readable defaults)
CLIENT_HTML_TMPL = r"""<!doctype html>
<html><head><meta charset="utf-8"><title>Client Report</title>
<style>
body{font-family:Arial,Helvetica,sans-serif;margin:24px;color:#222}
.header{display:flex;justify-content:space-between;align-items:center}
.title{font-size:22px;font-weight:700}
.pill{padding:4px 8px;border-radius:999px;background:#eef2ff;color:#3730a3;font-weight:600;font-size:12px}
h2{font-size:16px;margin:20px 0 8px}
.story{margin:8px 0;padding:8px;border:1px solid #eee;border-radius:8px;background:#fafafa}
.subtle{color:#666;font-size:12px}
.key{font-size:12px;color:#555}
.footer{margin-top:20px;color:#777;font-size:12px}
</style></head><body>
<div class="header"><div class="title">Client Report</div>
<div class="pill">{{ es.label_A }} vs {{ es.label_B }}</div></div>

<h2>Executive Summary</h2>
<ul>{% for h in es.highlights %}<li>{{ h }}</li>{% endfor %}</ul>

<h2>Top 10 Stories</h2>
{% for s in stories %}
  <div class="story"><div><strong>{{ s.line }}</strong></div>
  <div class="subtle">{{ s.kind }} ‚Äî {{ s.name }}</div>
  <div>{{ s.detail }}</div></div>
{% endfor %}

<h2>Final Overview</h2><p>{{ final_overview }}</p>

{% if style_key %}
<div class="key"><strong>Style Key:</strong><ul>
  {% for k in style_key %}<li>{{ k }}</li>{% endfor %}
</ul></div>
{% endif %}
<div class="footer">Generated by MMQB Reporting</div>
</body></html>"""

INTERNAL_HTML_TMPL = r"""<!doctype html>
<html><head><meta charset="utf-8"><title>Internal Report</title>
<style>
body{font-family:Arial,Helvetica,sans-serif;margin:20px;color:#222}
.header{display:flex;justify-content:space-between;align-items:center}
.title{font-size:22px;font-weight:700}
.pill{padding:4px 8px;border-radius:999px;background:#ecfeff;color:#155e75;font-weight:600;font-size:12px}
h2{font-size:16px;margin:20px 0 8px}
table{width:100%;border-collapse:collapse;margin-top:6px}
th,td{border:1px solid #eee;padding:6px 8px;font-size:12px;text-align:left}
th{background:#f8fafc}
.star{color:#ef4444;font-weight:bold}
.subtle{color:#666;font-size:12px}
.section{margin-bottom:16px}
</style></head><body>
<div class="header"><div class="title">Internal Report</div>
<div class="pill">{{ es.label_A }} vs {{ es.label_B }}</div></div>

<h2>Executive Summary</h2>
<table><thead><tr><th>Metric</th><th>A</th><th>B</th><th>Change</th></tr></thead>
<tbody>
{% for m in es.metrics %}
<tr><td>{{ m.name }}</td><td>{{ m.A_txt }}</td><td>{{ m.B_txt }}</td><td>{{ m.change }}</td></tr>
{% endfor %}
</tbody></table>

{% for section, rows in tables.items() %}
  <div class="section"><h2>{{ section|capitalize }}</h2>
  <table><thead><tr>
  <th>Name</th><th>Loads A</th><th>Loads B</th><th>Core OR A</th><th>Core OR B</th>
  <th>Œî Loads</th><th>Impact S</th><th>Impact D (000s)</th>
  <th>Dollarized S (000s)</th><th>Composite (000s)</th><th>Story</th>
  </tr></thead><tbody>
  {% for r in rows %}
  <tr>
    <td>{{ r.name }}</td><td>{{ r.loads_A }}</td><td>{{ r.loads_B }}</td>
    <td>{{ r.core_or_A_txt }}</td><td>{{ r.core_or_B_txt }}</td>
    <td>{{ r.d_loads }}</td>
    <td>{{ "%.2f"|format(r.impact_s) }}</td>
    <td>{{ "%.2f"|format(r.impact_d_000s) }}</td>
    <td>{{ "%.2f"|format(r.dollarized_s_000s) }}</td>
    <td>{{ "%.2f"|format(r.composite_000s) }}</td>
    <td>{% if r.star %}<span class="star">‚òÖ</span>{% endif %}</td>
  </tr>
  {% endfor %}
  </tbody></table></div>
{% endfor %}

<div class="subtle">* Asterisk on Core OR means substitution against network for that period.</div>
</body></html>"""

# ---------------------------------------------------
# HELPERS
# ---------------------------------------------------
def ensure_dirs():
    os.makedirs(INPUT_DIR, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)

def week_end_saturday(ts) -> datetime.date:
    d = pd.to_datetime(ts).normalize()
    wd = d.weekday()  # Mon=0..Sun=6
    offset = (5 - wd) % 7  # Saturday=5
    return (d + pd.Timedelta(days=offset)).date()

def mmddyy(d: datetime.date) -> str:
    return pd.to_datetime(d).strftime("%m-%d-%y")

def safe_int(x: float) -> int:
    return int(round(float(x or 0)))

def approx_tokens(s: str) -> int:
    return max(1, math.ceil(len(s) / 4))  # rough ‚âà 4 chars per token

def normalize_str(s):
    if pd.isna(s):
        return ""
    return str(s).strip()

def preprocess_df(df: pd.DataFrame) -> pd.DataFrame:
    for col in ["BILLTO_NAME", "ORIG_AREA", "DEST_AREA"]:
        if col in df.columns:
            df[col] = df[col].apply(normalize_str)
    return df

def render_html(template_str: str, context: dict) -> str:
    env = Environment(loader=BaseLoader(), autoescape=select_autoescape(["html"]))
    tmpl = env.from_string(template_str)
    return tmpl.render(**context)

def write_pdf_or_html(html_str: str, out_html_path: str, out_pdf_path: str | None):
    with open(out_html_path, "w", encoding="utf-8") as f:
        f.write(html_str)
    if HAVE_WEASY and out_pdf_path:
        try:
            HTML(string=html_str).write_pdf(out_pdf_path)
            return True
        except Exception as e:
            print(f"[!] PDF export failed: {e}")
            return False
    return False

# ---------------------------------------------------
# CSV LOADING & PERIODS
# ---------------------------------------------------
def load_csv(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    needed = {
        "DELIVERY_DT", "BILLTO_NAME", "ORIG_AREA", "DEST_AREA",
        "LOADED_OP_MILES", "TOTAL_REVENUE", "TOTAL_VARIABLE_COST", "TOTAL_OVERHEAD_COST"
    }
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise SystemExit(f"Missing columns: {missing}")
    df["DELIVERY_DT"] = pd.to_datetime(df["DELIVERY_DT"])
    df["WEEK_END"] = df["DELIVERY_DT"].apply(week_end_saturday)
    df["TOTAL_COST"] = df["TOTAL_VARIABLE_COST"] + df["TOTAL_OVERHEAD_COST"]
    df = preprocess_df(df)
    return df

def choose_periods(df: pd.DataFrame) -> Tuple[List, List]:
    sats = sorted(df["WEEK_END"].unique())
    N = len(sats)
    if N < 2:
        raise SystemExit("Need at least 2 distinct Saturdays in the data.")
    if N >= 8:
        A_sats, B_sats = sats[-4:], sats[-8:-4]
    elif 5 <= N <= 7:
        A_sats, B_sats = sats[-1:], sats[-(1+min(4, N-1)):-1]
    elif 3 <= N <= 4:
        A_sats, B_sats = sats[-1:], sats[:-1]
    else:
        A_sats, B_sats = sats[-1:], sats[-2:-1]
    return A_sats, B_sats

# ---------------------------------------------------
# METRICS
# ---------------------------------------------------
def network_block(g: pd.DataFrame) -> Dict[str, Any]:
    loads = len(g)
    rev   = g["TOTAL_REVENUE"].sum()
    varc  = g["TOTAL_VARIABLE_COST"].sum()
    oh    = g["TOTAL_OVERHEAD_COST"].sum()
    cost  = varc + oh
    loh   = float(g["LOADED_OP_MILES"].mean()) if loads > 0 else 0.0
    or_ratio = (cost / rev) if rev > 0 else 0.0
    rpl  = (rev / loads) if loads > 0 else 0.0
    varpl = (varc / loads) if loads > 0 else 0.0
    ohpl = (oh / loads) if loads > 0 else 0.0
    return dict(
        loads=int(loads), rev=safe_int(rev), var=safe_int(varc), oh=safe_int(oh),
        loh=safe_int(loh), or_pct=round(or_ratio*100.0, 1),
        rpl=safe_int(rpl), varpl=safe_int(varpl), ohpl=safe_int(ohpl)
    )

def weekly_equivalent(n_loads: int, n_weeks: int) -> float:
    return (n_loads / max(n_weeks, 1))

def table_rows(A: pd.DataFrame, B: pd.DataFrame,
               key_cols: List[str],
               namer) -> List[Dict[str, Any]]:
    rows = []

    A_grp = A.groupby(key_cols, dropna=False)
    B_grp = B.groupby(key_cols, dropna=False)
    keys = set(A_grp.groups.keys()) | set(B_grp.groups.keys())

    netA = network_block(A)
    netB = network_block(B)
    net_or_B  = netB["or_pct"] / 100.0
    net_mpl_B = ((netB["rev"] - (netB["var"] + netB["oh"])) / max(netB["loads"], 1))
    net_rpl_B = netB["rpl"]

    kA = len(A["WEEK_END"].unique())
    kB = len(B["WEEK_END"].unique())

    for k in keys:
        # Future-proof for single column groupby key
        key = (k,) if isinstance(k, (str, int, float)) and len(key_cols) == 1 else k
        GA = A_grp.get_group(key) if key in A_grp.groups else A.iloc[0:0]
        GB = B_grp.get_group(key) if key in B_grp.groups else B.iloc[0:0]

        L_A = len(GA); R_A = GA["TOTAL_REVENUE"].sum(); C_A = GA["TOTAL_COST"].sum()
        L_B = len(GB); R_B = GB["TOTAL_REVENUE"].sum(); C_B = GB["TOTAL_COST"].sum()

        OR_A = (C_A / R_A) if R_A > 0 else 0.0
        OR_B = (C_B / R_B) if R_B > 0 else 0.0
        MPL_A = ((R_A - C_A) / L_A) if L_A > 0 else 0.0
        MPL_B = ((R_B - C_B) / L_B) if L_B > 0 else 0.0
        RPL_A = (R_A / L_A) if L_A > 0 else 0.0
        RPL_B = (R_B / L_B) if L_B > 0 else 0.0

        OR_A_sub = (L_A == 0); OR_B_sub = (L_B == 0)
        OR_A_eff  = net_or_B  if OR_A_sub else OR_A
        OR_B_eff  = net_or_B  if OR_B_sub else OR_B
        MPL_A_eff = net_mpl_B if OR_A_sub else MPL_A
        MPL_B_eff = net_mpl_B if OR_B_sub else MPL_B
        RPL_A_eff = net_rpl_B if OR_A_sub else RPL_A
        RPL_B_eff = net_rpl_B if OR_B_sub else RPL_B

        LAw = weekly_equivalent(L_A, kA)
        LBw = weekly_equivalent(L_B, kB)
        AvgLoads = (LAw + LBw) / 2.0
        dLoads   = LAw - LBw
        AvgRPL   = (RPL_A_eff + RPL_B_eff) / 2.0

        impact_s = (OR_B_eff - OR_A_eff)*AvgLoads + (net_or_B - OR_B_eff)*dLoads
        impact_d = (MPL_A_eff - MPL_B_eff)*AvgLoads + (MPL_B_eff - net_mpl_B)*dLoads
        dollarized_s_000s = round((impact_s * AvgRPL) / 1000.0, 2)
        impact_d_000s     = round(impact_d / 1000.0, 2)

        f_quality   = min(abs(OR_B_eff - net_or_B)*100.0/5.0, 1.0)
        w_stability = math.sqrt(AvgLoads / (AvgLoads + 15.0)) if (AvgLoads + 15.0) > 0 else 0.0
        w_S         = 0.5 * f_quality * w_stability
        composite_raw = impact_d_000s + w_S * dollarized_s_000s

        # Conflict guardrail
        if (impact_d_000s * dollarized_s_000s) < 0 and abs(dollarized_s_000s) < 2*abs(impact_d_000s) and (composite_raw * impact_d_000s) < 0:
            composite_000s = abs(composite_raw) * (1 if impact_d_000s >= 0 else -1)
        else:
            composite_000s = composite_raw

        # 0.75% per-period filter (both periods <= threshold)
        thrA = 0.0075 * max(netA["loads"], 1)
        thrB = 0.0075 * max(netB["loads"], 1)
        if (L_A <= thrA) and (L_B <= thrB):
            continue

        rows.append({
            "name": namer(k),
            "loads_A": int(L_A), "loads_B": int(L_B),
            "core_or_A_txt": f"{round(OR_A_eff*100.0,1)}" + ("*" if OR_A_sub else ""),
            "core_or_B_txt": f"{round(OR_B_eff*100.0,1)}" + ("*" if OR_B_sub else ""),
            "d_loads": int(L_A - L_B),
            "impact_s": round(impact_s, 2),
            "impact_d_000s": impact_d_000s,
            "dollarized_s_000s": dollarized_s_000s,
            "composite_000s": round(composite_000s, 2),
            "star": False
        })

    rows.sort(key=lambda r: abs(r["composite_000s"]), reverse=True)
    return rows[:15]

def compute_aggregates(df: pd.DataFrame) -> Dict[str, Any]:
    A_sats, B_sats = choose_periods(df)
    A = df[df["WEEK_END"].isin(A_sats)].copy()
    B = df[df["WEEK_END"].isin(B_sats)].copy()

    netA = network_block(A)
    netB = network_block(B)

    customers = table_rows(A, B, ["BILLTO_NAME"], lambda k: k if isinstance(k, str) else str(k))
    lanes     = table_rows(A, B, ["ORIG_AREA", "DEST_AREA"], lambda k: f"{k[0]} \u2192 {k[1]}")
    outbound  = table_rows(A, B, ["ORIG_AREA"], lambda k: k if isinstance(k, str) else str(k))
    inbound   = table_rows(A, B, ["DEST_AREA"], lambda k: k if isinstance(k, str) else str(k))

    # Build cross-entity pool for Top-10
    pool=[]
    for t, arr in [("Customer", customers), ("Lane", lanes), ("Outbound Area", outbound), ("Inbound Area", inbound)]:
        for r in arr: pool.append((t, r))
    pool.sort(key=lambda x: abs(x[1]["composite_000s"]), reverse=True)

    top10=[]; seen=set()
    for t, r in pool:
        key=(t, r["name"])
        if key in seen:
            continue
        seen.add(key)
        top10.append({
          "kind": t,
          "name": r["name"],
          "or_A_pct": float(r["core_or_A_txt"].rstrip("*")),
          "or_B_pct": float(r["core_or_B_txt"].rstrip("*")),
          "loads_A": r["loads_A"], "loads_B": r["loads_B"],
          "composite_000s": r["composite_000s"],
          "or_A_sub": r["core_or_A_txt"].endswith("*"),
          "or_B_sub": r["core_or_B_txt"].endswith("*")
        })
        if len(top10) == 10: break

    # Star rows used in stories
    keys={(s["kind"], s["name"]) for s in top10}
    for kind, label in [("customers","Customer"),("lanes","Lane"),("outbound","Outbound Area"),("inbound","Inbound Area")]:
        for r in locals()[kind]:
            if (label, r["name"]) in keys: r["star"]=True

    meta = {
        "scale_mode": "WEEKLY", "L0": 15, "filter_threshold_pct": 0.0075,
        "periodA": {
            "start": str(min(A_sats)), "end": str(max(A_sats)),
            "weeks": len(A_sats), "saturday": str(max(A_sats))
        },
        "periodB": {
            "start": str(min(B_sats)), "end": str(max(B_sats)),
            "weeks": len(B_sats), "saturday": str(max(B_sats))
        },
        "rounding": {"or_dp":1,"impact_dp":2},
        "format": {"use_commas":True,"arrows":True}
    }

    return {
        "meta": meta,
        "network": {"A": netA, "B": netB},
        "tables": {"customers": customers, "lanes": lanes, "outbound": outbound, "inbound": inbound},
        "stories_top10": top10
    }

# ---------------------------------------------------
# CLIENT FALLBACKS (ensure completeness even if LLM skimps)
# ---------------------------------------------------
def make_client_highlights_from_network(label_A: str, label_B: str, netA: dict, netB: dict) -> Dict[str, Any]:
    def arrow(delta, better_when_down=False, units=""):
        if abs(delta) < 1e-9:
            return f"‚Üí flat"
        good = (delta < 0) if better_when_down else (delta > 0)
        sym = "‚ñ≤" if good else "‚ñº"
        if units == "pts":
            return f"{sym} {delta:.1f} pts"
        else:
            return f"{sym} {int(round(delta))}"
    highlights = []
    highlights.append(f"Load count: {netA['loads']:,} (A) vs {netB['loads']:,} (B) ‚Äî {arrow(netA['loads']-netB['loads'])}.")
    highlights.append(f"Core OR: {netA['or_pct']:.1f}% (A) vs {netB['or_pct']:.1f}% (B) ‚Äî {arrow(netA['or_pct']-netB['or_pct'], better_when_down=True, units='pts')}.")
    highlights.append(f"Revenue/Load: {netA['rpl']:,} (A) vs {netB['rpl']:,} (B) ‚Äî {arrow(netA['rpl']-netB['rpl'])}.")
    highlights.append(f"Overhead/Load: {netA['ohpl']:,} (A) vs {netB['ohpl']:,} (B) ‚Äî {arrow(netA['ohpl']-netB['ohpl'], better_when_down=True)}.")
    highlights.append(f"Variable/Load: {netA['varpl']:,} (A) vs {netB['varpl']:,} (B) ‚Äî {arrow(netA['varpl']-netB['varpl'], better_when_down=True)}.")
    return {"label_A": label_A, "label_B": label_B, "highlights": highlights}

def make_final_overview(netA: dict, netB: dict, tables: dict) -> str:
    or_delta = netA["or_pct"] - netB["or_pct"]  # negative = improved
    direction = "profitability improved" if or_delta < 0 else ("held about flat" if abs(or_delta) < 0.1 else "profitability worsened")
    movers = []
    for kind, rows in tables.items():
        for r in rows:
            movers.append((kind, r["name"], r["composite_000s"]))
    movers.sort(key=lambda x: abs(x[2]), reverse=True)
    top = movers[:3]
    pieces = []
    pieces.append(f"Overall, {direction} from Period B to A (Core OR {netB['or_pct']:.1f}% ‚Üí {netA['or_pct']:.1f}%).")
    if top:
        labels = [f"{k.rstrip('s').title()} '{n}' ({v:+.0f}k)" for k,n,v in top]
        pieces.append("Largest drivers by Composite: " + "; ".join(labels) + ".")
    load_delta = netA["loads"] - netB["loads"]
    rpl_delta  = netA["rpl"] - netB["rpl"]
    trend_bits = []
    if load_delta != 0:
        trend_bits.append(f"loads {'up' if load_delta>0 else 'down'} {abs(load_delta):,}")
    if rpl_delta != 0:
        trend_bits.append(f"revenue/load {'up' if rpl_delta>0 else 'down'} {abs(int(round(rpl_delta))):,}")
    if trend_bits:
        pieces.append("Volume and rate context: " + ", ".join(trend_bits) + ".")
    return " ".join(pieces)

# ---------------------------------------------------
# NARRATIVE (LLM) ‚Äî your full system_instructions
# ---------------------------------------------------
SYSTEM_INSTRUCTIONS = r"""You are the Weekly Profitability Report engine for an over-the-road trucking company.

DO NOT recompute metrics yourself. Always call the tool `compute_aggregates` to read the CSV and calculate:
- period selection (dynamic), weekly normalization, and all scores
- tables for Customer / Lane / Outbound Area / Inbound Area (sorted by |Composite|)
- network executive summary labels and numbers
- Top-10 cross-entity stories + driver detail candidates

## Dynamic periods (based on distinct Saturday week-ends in the CSV)
Let N = number of distinct Saturdays present.
- If N ‚â• 8: Period A = last 4 weeks; Period B = prior 4 weeks.
- If 5‚Äì7:   Period A = last 1 week;  Period B = prior min(4, N‚àí1) weeks (averaged).
- If 3‚Äì4:   Period A = last 1 week;  Period B = all prior weeks (averaged).
- If 2:     Period A = last 1 week;  Period B = prior 1 week.

Weeks are Sunday‚ÄìSaturday; each week is identified by its Saturday date.

## Normalization and stability
- Always compute **weekly-equivalent normalization** for loads (impacts are per-week).
- Keep L0 = 15 (weekly basis) for the stability weight.

## Scoring & rules (computed by the tool; you only format/use them)
- Core OR (ratio) = (Variable + Overhead Cost) / Revenue; display as percent with 1 decimal.
- MPL = (Revenue ‚àí Total Cost) / Loads; RPL = Revenue / Loads.
- Impact_S = (OR_B ‚àí OR_A)√óAvg_Loads + (Network_OR_B ‚àí OR_B)√óŒîLoads
- Impact_D = (MPL_A ‚àí MPL_B)√óAvg_Loads + (MPL_B ‚àí Network_MPL_B)√óŒîLoads
- Dollarized_S = Impact_S √ó Avg_RPL; report **Impact_D** and **Dollarized_S** in **(000s)** with 2 decimals.
- Composite (000s) = Impact_D(000s) + w_S √ó Dollarized_S(000s), with:
  f_quality = min(|OR_B ‚àí Network_OR_B|√ó100/5, 1.0),
  w_stability = sqrt(Avg_Loads / (Avg_Loads + L0)),
  w_S = 0.5 √ó f_quality √ó w_stability.
- Conflict guardrail: if Impact_D and Dollarized_S disagree, |$S| < 2√ó|D|, and their sum would flip D‚Äôs sign, snap Composite‚Äôs sign to match Impact_D (keep sum‚Äôs magnitude).
- Filter: Exclude a group ONLY if BOTH periods have loads ‚â§ 0.75% of that period‚Äôs network loads.
- Substitution: If a group has 0 loads in a period, the tool substitutes Period-B network OR/MPL/RPL for that period; Core OR cells show ‚Äú*‚Äù in the internal table. Only mention ‚Äúcompared against network Core OR‚Äù in a story when substitution actually occurred for that entity/period.

## Executive summary formatting
- Columns use Saturday labels with window size: e.g., ‚Äú08/30/25 (1wk)‚Äù vs ‚Äú08/23/25 (4wk)‚Äù.
- ‚ÄúChange‚Äù column uses arrows: ‚ñ≤ positive (helped), ‚ñº negative (hurt), ‚Üí neutral.
- Use commas for thousands; no decimals except on Core OR.

## Internal tables
- Use the pre-sorted rows from the tool (already by |Composite| descending). Do not re-sort.
- Remove ‚ÄúAvg Loads‚Äù column. Show Core OR values with ‚Äú*‚Äù where substitution happened.
- Star the 10 rows used in stories (the tool flags these).

## Client-facing Top-10 stories
- Choose across all entities by |Composite| (no duplicates).
- Begin each story with an arrow: ‚ñ≤ helped, ‚ñº hurt, ‚Üí neutral.
- Tone is conversational: say ‚ÄúCore OR improved‚Äù when OR% decreased; ‚Äúworsened‚Äù when OR% increased; ‚Äúheld‚Äù when flat.
- Mention ‚Äúcompared against network Core OR‚Äù only when a substitution occurred for that entity/period.
- Include a short driver detail line:
  ‚Ä¢ If story entity is a **Customer** ‚Üí identify the **Lane** with the largest |Composite|.
  ‚Ä¢ If **Lane** ‚Üí identify the most impactful **Bill To (customer)**.
  ‚Ä¢ If **Area** (Outbound/Inbound) ‚Üí identify whichever (**Lane** or **Customer**) has the largest |Composite| within that area (or closest proxy provided by the tool).

## Client-facing FINAL WORD (new)
After the Top-10 stories, add a **1‚Äì4 sentence ‚Äúfinal overview‚Äù** that gives the clear headline on profitability from Period B ‚Üí Period A. Address direction (helped/hurt/flat), briefly cite the largest driver types (e.g., OR improvement vs margin/volume shifts), and keep it concise and plain-English. Do not restate every number; synthesize what changed and why it mattered.

## Output (Structured)
Return a single JSON object containing:
- `internal_report` (strict schema)
- `client_report`  (strict schema, includes `final_overview`)
- `filenames` with the two file names, exactly:
  `<CLIENTCODE>_<A_SAT>-<A_WEEKS>wk_vs_<B_SAT>-<B_WEEKS>wk_client.json`
  `<CLIENTCODE>_<A_SAT>-<A_WEEKS>wk_vs_<B_SAT>-<B_WEEKS>wk_internal.json`
Date parts are MM-DD-YY.

If you need data, first call `compute_aggregates` and wait for its result. Then use ONLY the values it returns. Do not invent numbers or re-compute.
"""

def build_client_and_internal_reports(client: OpenAI, model: str, calc: Dict[str, Any]) -> Dict[str, Any]:
    # Build labels
    a_sat = datetime.fromisoformat(calc["meta"]["periodA"]["saturday"])
    b_sat = datetime.fromisoformat(calc["meta"]["periodB"]["saturday"])
    label_A = f'{mmddyy(a_sat.date())} ({calc["meta"]["periodA"]["weeks"]}wk)'
    label_B = f'{mmddyy(b_sat.date())} ({calc["meta"]["periodB"]["weeks"]}wk)'

    netA = calc["network"]["A"]; netB = calc["network"]["B"]
    facts = {
        "label_A": label_A,
        "label_B": label_B,
        "network": {"A": netA, "B": netB},
        "top10": calc["stories_top10"],
        "tables": calc["tables"]
    }

    # Ask model to write narrative JSON (we keep fallbacks in case it skimps)
    messages = [
        {"role": "system", "content": SYSTEM_INSTRUCTIONS},
        {"role": "user", "content": json.dumps(facts)}
    ]
    params = dict(model=model, messages=messages)
    if TEMPERATURE is not None:
        params["temperature"] = TEMPERATURE

    resp = client.chat.completions.create(**params)
    text = (resp.choices[0].message.content or "").strip()
    if text.startswith("```"):
        text = re.sub(r"^```(?:json)?\s*", "", text)
        text = re.sub(r"\s*```$", "", text)
    try:
        data = json.loads(text)
    except Exception:
        # very rare; provide minimal shells so the render still works
        data = {"internal_report": {}, "client_report": {}}

    # INTERNAL: use model output if present; otherwise minimal shell + our tables
    internal_es = (data.get("internal_report", {}) or {}).get("executive_summary")
    if not internal_es:
        internal_es = {
            "label_A": label_A, "label_B": label_B,
            "metrics": [
                {"name":"Load Count","A_txt":f"{netA['loads']:,}","B_txt":f"{netB['loads']:,}","change":""},
                {"name":"Core OR","A_txt":f"{netA['or_pct']:.1f}%","B_txt":f"{netB['or_pct']:.1f}%","change":""},
                {"name":"Revenue/Load","A_txt":f"{netA['rpl']:,}","B_txt":f"{netB['rpl']:,}","change":""},
                {"name":"Overhead/Load","A_txt":f"{netA['ohpl']:,}","B_txt":f"{netB['ohpl']:,}","change":""},
                {"name":"Variable/Load","A_txt":f"{netA['varpl']:,}","B_txt":f"{netB['varpl']:,}","change":""},
                {"name":"LOH","A_txt":f"{netA['loh']:,}","B_txt":f"{netB['loh']:,}","change":""},
            ]
        }
    internal = {"executive_summary": internal_es, "tables": calc["tables"]}

    # CLIENT: guaranteed executive summary + final overview
    client_es = (data.get("client_report", {}) or {}).get("executive_summary")
    if not client_es or not isinstance(client_es.get("highlights", None), list) or len(client_es["highlights"]) == 0:
        client_es = make_client_highlights_from_network(label_A, label_B, netA, netB)

    client_report = {
        "executive_summary": client_es,
        "stories_top10": (data.get("client_report", {}) or {}).get("stories_top10", []),
        "final_overview": (data.get("client_report", {}) or {}).get("final_overview") or make_final_overview(netA, netB, calc["tables"]),
        "style_key": (data.get("client_report", {}) or {}).get("style_key", [
            "‚ñ≤ helped network profitability", "‚ñº hurt network profitability", "‚Üí neutral",
            "Say ‚ÄúCore OR improved‚Äù when OR% decreased; ‚Äúworsened‚Äù when OR% increased; ‚Äúheld‚Äù when flat.",
            "Mention ‚Äúcompared against network Core OR‚Äù only when asterisks indicate a substituted network value."
        ])
    }
    return {"internal_report": internal, "client_report": client_report}

# ---------------------------------------------------
# FILENAMES & SAVE
# ---------------------------------------------------
def filenames_for(client_code: str, calc: Dict[str, Any]) -> Dict[str, str]:
    a_sat = datetime.fromisoformat(calc["meta"]["periodA"]["saturday"]).date()
    b_sat = datetime.fromisoformat(calc["meta"]["periodB"]["saturday"]).date()
    a_lab = f"{mmddyy(a_sat)}-{calc['meta']['periodA']['weeks']}wk"
    b_lab = f"{mmddyy(b_sat)}-{calc['meta']['periodB']['weeks']}wk"
    return {
        "client_json":  f"{client_code}_{a_lab}_vs_{b_lab}_client.json",
        "internal_json":f"{client_code}_{a_lab}_vs_{b_lab}_internal.json"
    }

def save_json_reports(bundle: Dict[str, Any]):
    ensure_dirs()
    with open(os.path.join(OUTPUT_DIR, bundle["filenames"]["client_json"]), "w", encoding="utf-8") as f:
        json.dump(bundle["client_report"], f, ensure_ascii=False, indent=2)
    with open(os.path.join(OUTPUT_DIR, bundle["filenames"]["internal_json"]), "w", encoding="utf-8") as f:
        json.dump(bundle["internal_report"], f, ensure_ascii=False, indent=2)

# ---------------------------------------------------
# MAIN
# ---------------------------------------------------
def main():
    ensure_dirs()

    parser = argparse.ArgumentParser(description="Generate client & internal reports (JSON) from CSV, plus optional PDFs.")
    parser.add_argument("--client", required=True, help="Client code (e.g., ADSJ).")
    parser.add_argument("--csv", required=True, help="CSV filename in the 'in/' folder, e.g., SCAC_YYYYMMDD_OpenAIAPI.csv")
    parser.add_argument("--pdf", action="store_true", help="Also render Client & Internal PDFs in 'out/' (fallback to HTML if PDF libs missing).")
    parser.add_argument("--model", default=DEFAULT_MODEL, help=f"Model for narrative (default: {DEFAULT_MODEL})")
    args = parser.parse_args()

    # Enforce filename pattern
    m = re.match(r"^(?P<scac>[A-Za-z0-9]+)_(?P<date>\d{8})_OpenAIAPI\.csv$", args.csv)
    if not m:
        raise SystemExit("CSV filename must match SCAC_YYYYMMDD_OpenAIAPI.csv")

    csv_path = os.path.join(INPUT_DIR, args.csv)
    if not os.path.exists(csv_path):
        raise SystemExit(f"CSV not found: {csv_path}")

    # Load + compute
    df = load_csv(csv_path)
    calc = compute_aggregates(df)

    # Auth preflight
    key = os.getenv("OPENAI_API_KEY") or ""
    proj = os.getenv("OPENAI_PROJECT")
    org  = os.getenv("OPENAI_ORG_ID")
    print("Auth preflight:", "key="+(key[:12]+"‚Ä¶"), "project="+(proj or "<none>"), "org="+(org or "<none>"))

    client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        project=os.getenv("OPENAI_PROJECT"),
        # organization=os.getenv("OPENAI_ORG_ID"),  # optional
    )

    # Optional: confirm model visible
    try:
        models = client.models.list()
        have_model = any(m.id == args.model for m in models.data)
        print(f"Models retrieved. {args.model} available:", have_model)
    except Exception as e:
        raise SystemExit(f"OpenAI auth/models check failed: {e!r}")

    # Narrative build (LLM with strong fallbacks)
    reports = build_client_and_internal_reports(client, args.model, calc)

    # Filenames + save JSON
    files = filenames_for(args.client, calc)
    bundle = {"filenames": files, **reports}
    save_json_reports(bundle)

    print("‚úÖ Wrote JSON:")
    print("  ", os.path.join(OUTPUT_DIR, files["client_json"]))
    print("  ", os.path.join(OUTPUT_DIR, files["internal_json"]))

    # PDFs/HTML (optional)
    if args.pdf:
        client_json_path = os.path.join(OUTPUT_DIR, files["client_json"])
        internal_json_path = os.path.join(OUTPUT_DIR, files["internal_json"])

        with open(client_json_path, "r", encoding="utf-8") as f:
            client_json = json.load(f)
        with open(internal_json_path, "r", encoding="utf-8") as f:
            internal_json = json.load(f)

        # client
        client_ctx = {
            "es": client_json["executive_summary"],
            "stories": client_json.get("stories_top10", []),
            "final_overview": client_json.get("final_overview", ""),
            "style_key": client_json.get("style_key", []),
        }
        client_html = render_html(CLIENT_HTML_TMPL, client_ctx)
        prefix = files["client_json"].split("_")[0]
        client_html_out = os.path.join(OUTPUT_DIR, f"{prefix}_client.html")
        client_pdf_out  = os.path.join(OUTPUT_DIR, f"{prefix}_client.pdf")
        client_pdf_ok = write_pdf_or_html(client_html, client_html_out, client_pdf_out)

        # internal
        internal_ctx = {"es": internal_json["executive_summary"], "tables": internal_json.get("tables", {})}
        internal_html = render_html(INTERNAL_HTML_TMPL, internal_ctx)
        internal_html_out = os.path.join(OUTPUT_DIR, f"{prefix}_internal.html")
        internal_pdf_out  = os.path.join(OUTPUT_DIR, f"{prefix}_internal.pdf")
        internal_pdf_ok = write_pdf_or_html(internal_html, internal_html_out, internal_pdf_out)

        print("üñ® Rendered:")
        print("  ", client_html_out, "‚Üí", (client_pdf_out if client_pdf_ok else "open HTML and Print to PDF"))
        print("  ", internal_html_out, "‚Üí", (internal_pdf_out if internal_pdf_ok else "open HTML and Print to PDF"))

    # token hint
    est_in_tokens = approx_tokens(json.dumps({"network": calc["network"], "top10": calc["stories_top10"]}))
    print(f"‚ÑπÔ∏è Rough input tokens to model: ~{est_in_tokens:,}")

if __name__ == "__main__":
    main()
